{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d229d2d-783d-4ee7-8f10-baa3d3d206b8",
   "metadata": {},
   "source": [
    "## GWAS Template\n",
    "\n",
    "Feel free to modify the template below to perform your own GWAS. Be sure to pay attention to the file paths for data imports/exports and specific QC metrics you wish to use prior to running the GWAS regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa889a5-3951-43ff-83e0-e974223b8e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import statements allow us to reuse code written previously by ourselves or others. \n",
    "Here we are importing the \"Hail\" library which is the core strategy we are going to be using to organize our data and to eventually perform statistical analyses.\n",
    "\"\"\"\n",
    "import hail as hl\n",
    "from hail.plot import show\n",
    "from pprint import pprint\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "%matplotlib inline\n",
    "hl.stop()\n",
    "hl.plot.output_notebook()\n",
    "hl.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57614d03-1b4d-4219-acda-33b213736da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this line if your data is in VCF format and needs to be converted to a Hail MatrixTable\n",
    "# hl.import_vcf('../data/1kg.vcf.bgz').write('../data/1kg.mt', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eece8c5-66b2-4abf-9a0b-8e3903606353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the genotype data from our \"data\" folder and storing it in a variable called \"mt\", short for \"MatrixTable\" (one of the key innovations of the Hail library)\n",
    "mt = hl.read_matrix_table('../data/1kg.mt')\n",
    "\n",
    "# Loading in the phenotype data from our \"data\" folder and storing it in a variable called \"table\", you can open the \"1kg_annotations.txt\" file if you want to see the format of how phenotypes could be stored\n",
    "table = hl.import_table('../data/1kg_annotations.txt', impute=True).key_by('Sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60e3ac-2720-4b5b-8c50-6dbd9f6dd6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the \"annotate_cols\" function to add our phenotype data in the \"table\" variable \n",
    "mt = mt.annotate_cols(pheno = table[mt.s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e37849-fc21-4529-9ffa-4ad8dbf190b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling Hail's built in QC functions for both the samples and the variants\n",
    "mt = hl.sample_qc(mt)\n",
    "mt = hl.variant_qc(mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f9b6d-f4d8-4bd6-8996-4c154fd37553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering column data using QC metrics such as call rate\n",
    "mt = mt.filter_cols((mt.sample_qc.dp_stats.mean >= 4) & (mt.sample_qc.call_rate >= 0.97))\n",
    "ab = mt.AD[1] / hl.sum(mt.AD)\n",
    "filter_condition_ab = ((mt.GT.is_hom_ref() & (ab <= 0.1)) |\n",
    "                        (mt.GT.is_het() & (ab >= 0.25) & (ab <= 0.75)) |\n",
    "                        (mt.GT.is_hom_var() & (ab >= 0.9)))\n",
    "mt = mt.filter_entries(filter_condition_ab)\n",
    "# Filtering row data using QC metrics such as minor allele frequency and Hardy-Weinberg Equilibrium\n",
    "mt = mt.filter_rows(mt.variant_qc.AF[1] > 0.01)\n",
    "mt = mt.filter_rows(mt.variant_qc.p_value_hwe > 1e-6)\n",
    "print('After filtering: Samples: %d  Variants: %d' % (mt.count_cols(), mt.count_rows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda3a86d-b253-4a03-9aa7-0707fdec3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating PCs and adding them as column variables\n",
    "eigenvalues, pcs, _ = hl.hwe_normalized_pca(mt.GT)\n",
    "\n",
    "mt = mt.annotate_cols(scores = pcs[mt.s].scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d89114-6407-4a08-994c-238773d66d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running GWAS with multiple co-variates\n",
    "gwas = hl.linear_regression_rows(\n",
    "    y=mt.pheno.CaffeineConsumption,\n",
    "    x=mt.GT.n_alt_alleles(),\n",
    "    covariates=[1.0, mt.pheno.isFemale, mt.scores[0], mt.scores[1], mt.scores[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe50241-58f4-4169-9dd7-337c31b838e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results\n",
    "p = hl.plot.manhattan(gwas.p_value)\n",
    "show(p)\n",
    "\n",
    "p = hl.plot.qq(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00d3ba9-cd7b-480a-ae54-5b6ae93e3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to save the GWAS results into a HailTable for later usage\n",
    "# gwas.write('..data/gwas_results.ht', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

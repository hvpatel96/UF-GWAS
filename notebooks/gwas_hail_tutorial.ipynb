{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b8d136-8d8b-4602-bcf2-a7281766d8dc",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "8b466d11-e569-4a91-87fd-771e70bce1bc",
     "isComponent": false,
     "name": "",
     "parents": []
    },
    "tags": []
   },
   "source": [
    "# GWAS Tutorial\n",
    "\n",
    "### 1. Setting up work environment\n",
    "The first step of performing a GWAS is to load in our depedencies and set up our work environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d1864-c385-4ac0-92fd-730e1c7fbb8b",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "420b6224-354a-41ab-911f-0b9f85782623",
     "isComponent": true,
     "name": "Initialize Hail",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import statements allow us to reuse code written previously by ourselves or others. \n",
    "Here we are importing the \"Hail\" library which is the core strategy we are going to be using to organize our data and to eventually perform statistical analyses.\n",
    "\"\"\"\n",
    "import hail as hl\n",
    "from hail.plot import show\n",
    "from pprint import pprint\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "%matplotlib inline\n",
    "start = time.time()\n",
    "hl.stop()\n",
    "hl.plot.output_notebook()\n",
    "hl.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e7d3d8-ad6c-4c78-a730-050d9579cba2",
   "metadata": {},
   "source": [
    "### 2. Loading in the data\n",
    "After we finish loading our dependencies, we can go ahead and start loading the data, starting with our genotype data (stored in a folder called \"1kg.mt\") and our phenotype data (stored in a file called \"1kg_annotations.txt\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728681a-58e3-421a-9cfc-0a740f9305ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the genotype data from our \"data\" folder and storing it in a variable called \"mt\", short for \"MatrixTable\" (one of the key innovations of the Hail library)\n",
    "mt = hl.read_matrix_table('data/1kg.mt')\n",
    "\n",
    "# Loading in the phenotype data from our \"data\" folder and storing it in a variable called \"table\"\n",
    "table = hl.import_table('data/1kg_annotations.txt', impute=True).key_by('Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de1b2f0-48fa-4fa9-82c9-528d7d7e0392",
   "metadata": {},
   "source": [
    "Now that our data is loaded in, we can combine the two to form a consolidated dataset containing all the relevant information we are going to use for our analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6319308d-0e0e-4b7d-a826-959194635ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the \"annotate_cols\" function to add our phenotype data in the \"table\" variable \n",
    "mt = mt.annotate_cols(pheno = table[mt.s])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed50743-43f0-4679-ba26-aecdc5c59cdc",
   "metadata": {},
   "source": [
    "It is always a good idea to take a look at our data to see what format we are working with and the available information we have. One way to do this is by using the \"describe\" method. An example is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d80572-3465-4a7f-b2d7-b72520df7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the format of the \"mt variable\" using an interactive widget\n",
    "mt.describe(widget = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49ceab1-4616-4f14-8bf5-b714e4319225",
   "metadata": {},
   "source": [
    "After running the cell above, we can now interact with the four main components of our dataset (globals, rows, cols, and entries). In Hail, each row consist of one specific genetic variant and each column consist of one specific individual. An entry is an intersection of a row and a column and contains information about a specific variant for a particular individual (such as the genetic call).\n",
    "\n",
    "Additionally from the interactive cell above, we can see that in the \"col\" tab, we have two fields that we can access: \"s\" and \"pheno\". If we expand the \"pheno\" field, we can see what information we have available for each individual. In this dataset, we have access to the following variables for each individual: \"Population\", \"SuperPopulation\", \"isFemale\", \"PurpleHair\", and \"CaffeineConsumption\". \n",
    "\n",
    "Feel free to explore the \"row\" and \"entry\" tabs to learn more about those parts of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253bec6d-8864-4512-b51e-2ff2e8924fe8",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "2d36dca8-9d16-4262-8ada-2c635aebf92d",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "### 3. Quality Control\n",
    "\n",
    "After we load and explore our dataset, the next step is to perform some quality control (QC) so that we have a clean dataset prior to statistical analysis. In a GWAS, there are quite a few quality control measures we have to do. For this tutorial, we will focus on just a few QC measures. In order to organize ourselves, let's split these quality control measures into two categories: QC on the sample data and QC on the variant data.\n",
    "\n",
    "Let's begin with QC on the sample (phenotype) data:\n",
    "1. Remove individuals with high levels of missingness (people who we do not have enough data for)\n",
    "\n",
    "Let's continue on to QC on the variant (genotype) data:\n",
    "1. Remove variants with low minor allele frequency (MAF)\n",
    "2. Remove variants that deviate from Hardy–Weinberg equilibrium (HWE)\n",
    "\n",
    "Hail has a few QC methods that can help us get started. These methods, **sample_qc** and **variant_qc**, extract quality-related information from our MatrixTable and store them into variables that we can later reference. While we are at it, let's also create another variable (filtered_mt) that will hold the filtered version of our MatrixTable after QC.\n",
    "\n",
    "If you want more information on QC on GWAS data, including definition and best practices of the above QC terms, please check out the following paper by [Marees et al.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6001694/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876a95d-cefd-4ca2-8113-d700681c7f23",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "05b0adb7-effd-4822-88f7-595b1c8b07d4",
     "isComponent": true,
     "name": "Variant QC",
     "parents": [
      {
       "id": "420b6224-354a-41ab-911f-0b9f85782623",
       "name": "Initialize Hail"
      }
     ]
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Calling Hail's built in QC functions for both the samples and the variants\n",
    "mt = hl.sample_qc(mt)\n",
    "mt = hl.variant_qc(mt)\n",
    "filtered_mt = mt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd5b987-9f0c-4d96-bae8-f4f55bf91ce0",
   "metadata": {},
   "source": [
    "We can now use Hail's filter_rows and filter_cols methods to filter out bad samples and bad variants from our MatrixTable. To make it easier to follow, running the cell below creates sliders that you can drag to select different threshold values for our QC conditions above. Feel free to change the values and then click on the button to apply the QC filters. Also take some time to check out the commented portion of the code to dive deeper in the syntax used by Hail to perform filtering. Notice how the number of samples and variants change depending on our threshold values.\n",
    "\n",
    "When you are done experimenting, configure the sliders to the following QC values and click on the button: \n",
    "1. **Sample Call Rate = 0.97** (Call rate refers to the fraction of called SNPs over the total number of SNPs in the dataset. Samples will low call rate have a ton of missing SNPs/data and should be removed from the final analysis).\n",
    "2. **Minor Allele Frequency = 0.01** (Minor Allele Frequency (MAF) refers to the frequency at which the second most common allele occurs in a given population. Lower MAF indiciates that a SNP is rare in a population. As we are focusing on more common variants for this tutorial, it is important to remove the really rare ones.)\n",
    "3. **Hardy Weinberg Equilibrium = 1.00e-6** (Hardy Weinberg Equilbrium (HWE) is a fundamental concept in population genetics and refers to the concept that genotype frequencies in a population remain constant between generations in the absence of disturbance by outside factors. We can utilize HWE to test for genotyping errors by comparing our dataset allele frequencies with that of a theoretical dataset.)\n",
    "\n",
    "The code cell below is fairly large as it is handling both the behavior of creating the interactive buttons and the actual filtering. Mostly focus on the commented lines rather than trying to understand the entire code cell at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d47ce18-88ba-4a10-b60d-311de09e2ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The code below creates the different sliders that you can interact with. We have a slider for each of the QC variables and finally a button to run the QC steps.\n",
    "call_rate_slider = widgets.FloatSlider(min=0.90, max=1.00, step=0.01, value=0.97, layout = widgets.Layout(width='500px'), description = \"Sample Call Rate:\", style=dict(description_width='initial'))\n",
    "maf_slider = widgets.FloatSlider(min=0.01, max=0.10, step=0.01, value=0.01, layout = widgets.Layout(width='500px'), description = \"Minor Allele Frequency:\", style=dict(description_width='initial'))\n",
    "hwe_slider = widgets.FloatLogSlider(value=6, base=10, min=-10, max=-6, step=1, readout_format='.2e', layout = widgets.Layout(width='500px'), description = \"Hardy Weinberg Equilbrium:\", style=dict(description_width='initial'))\n",
    "output = widgets.Output()\n",
    "button = widgets.Button(description = \"Apply QC filter\", button_style = \"primary\")\n",
    "\n",
    "display(call_rate_slider, maf_slider, hwe_slider)\n",
    "display(button)\n",
    "\n",
    "# This method is what takes the values from the sliders once the button is pressed and passes them into Hail's filtering methods.\n",
    "def on_button_click(a):\n",
    "    global mt\n",
    "    global filtered_mt\n",
    "    filtered_mt = mt\n",
    "    with output:\n",
    "        clear_output()\n",
    "        call_rate_value = call_rate_slider.value\n",
    "        maf_value = maf_slider.value\n",
    "        hwe_value = hwe_slider.value\n",
    "        # The line below filters the columns of our MatrixTable and removes samples whose call rate is below the specified value (in our case 0.97).\n",
    "        filtered_mt = filtered_mt.filter_cols((filtered_mt.sample_qc.dp_stats.mean >= 4) & (filtered_mt.sample_qc.call_rate >= call_rate_value))\n",
    "        ab = filtered_mt.AD[1] / hl.sum(filtered_mt.AD)\n",
    "        filter_condition_ab = ((filtered_mt.GT.is_hom_ref() & (ab <= 0.1)) |\n",
    "                        (filtered_mt.GT.is_het() & (ab >= 0.25) & (ab <= 0.75)) |\n",
    "                        (filtered_mt.GT.is_hom_var() & (ab >= 0.9)))\n",
    "        filtered_mt = filtered_mt.filter_entries(filter_condition_ab)\n",
    "        # The line below filters the rows of our MatrixTable and removes variants whose minor allele frequency is below the specified value (in our case 0.01)\n",
    "        filtered_mt = filtered_mt.filter_rows(filtered_mt.variant_qc.AF[1] > maf_value)\n",
    "        # The line below filters the rows of our MatrixTable and removes variants whose Hardy-Weinberg equilirbrium value is below the specified value (in our case 1e-6)\n",
    "        filtered_mt = filtered_mt.filter_rows(filtered_mt.variant_qc.p_value_hwe > hwe_value)\n",
    "        print('After filtering: Samples: %d  Variants: %d' % (filtered_mt.count_cols(), filtered_mt.count_rows()))\n",
    "button.on_click(on_button_click)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c9c489-52e0-491e-b8ad-7bdfe19a1d9c",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "a8d9e92e-f2d4-4264-aa00-52c35a666907",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "### 4. Initial GWAS\n",
    "\n",
    "Now that we are done filtering our data, we can go ahead and perform the actual GWAS! In Hail, a GWAS can be performed using the **hl.linear_regression_rows or hl.logistic_regression_rows** methods. The decision to use which method depends on what kind of phenotype we want to investigate. For this tutorial, let us investigate the CaffeineConsumption phenotype (a synthetic phenotype created just for the purpose of this tutorial). As the CaffeineConsumption phenotype is an integer and not a boolean (True/False), we will use the **hl.linear_regression_rows** method for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e9466-ffde-48b1-bb6d-734990275f7a",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "5e99a5d7-8f9b-48cb-a536-8eff8a0b8a75",
     "isComponent": true,
     "name": "GWAS",
     "parents": [
      {
       "id": "05b0adb7-effd-4822-88f7-595b1c8b07d4",
       "name": "Variant QC"
      },
      {
       "id": "420b6224-354a-41ab-911f-0b9f85782623",
       "name": "Initialize Hail"
      }
     ]
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here is where we actually run our GWAS!\n",
    "gwas = hl.linear_regression_rows(\n",
    "    y=filtered_mt.pheno.CaffeineConsumption,\n",
    "    x=filtered_mt.GT.n_alt_alleles(),\n",
    "    covariates=[1.0, filtered_mt.pheno.isFemale])\n",
    "p = hl.plot.manhattan(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b43d501-5d39-4e88-ab79-7c8a632805de",
   "metadata": {},
   "source": [
    "The image above is called a Manhattan plot, named after the city skyline of Manhattan, NY. Each point represents one particular variant in our dataset. Variants that have higher y-values are more statistically significant. The dashed horizontal line presents our significance threshold (5e-8). Examples of well controlled GWAS's Manhattan plots from other published studies are provided below:\n",
    "\n",
    "<img src=\"https://ars.els-cdn.com/content/image/3-s2.0-B9780123742797130206-f13020-01-9780123742797.jpg\" alt=\"Manhattan Image1\"/>\n",
    "<img src=\"https://ars.els-cdn.com/content/image/3-s2.0-B9780128209516000132-f08-03-9780128209516.jpg\" alt=\"Manhattan Image2\"/>\n",
    "\n",
    "Source: https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/manhattan-plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70543942-9d3a-4085-a1be-f58bd5d7588b",
   "metadata": {},
   "source": [
    "In both of the examples above, most of the variants are not significant and are tightly packed together. However, this is not what we see in our GWAS. What's wrong? Is there something in our dataset that is adding noise to our GWAS? We can investigate for potential confounding effects by using a Quantile-Quantile Plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be01a210-974e-4de9-a399-a4cf6e03a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = hl.plot.qq(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0297839-b73b-4a05-ba4c-b681a01e7c9c",
   "metadata": {},
   "source": [
    "A Quantile-Quantile plot (or QQ-plot) is a graph that represents of the deviation of the observed p-values from the null hypothesis. The GWAS p-values for each SNP are sorted from largest to smallest and plotted against expected values from a theoretical χ2-distribution. ***If the observed values correspond to the expected values, all points are on or near the middle line between the x-axis and the y-axis (null hypothesis).*** In our case, we see that our points deviate greatly from the middle line. This is evidence of potential confounding present in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5477ae47-99c7-48ba-a6c0-1888efa2586a",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "f7f58c92-51d1-4bf2-981c-e305a2dd9f94",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "source": [
    "### 4. Ancestry, Population Stratification and Principal Component Analysis (PCA)\n",
    "\n",
    "One's ancestry has a large role in determining the genetic variants present in one's genome. Depending on the ancestry, variants can have differing influence on the phenotype being explored. Often times in genomic studies, researchers will control for ancestry in their statistical experiments. We do this in order to account for population stratification (differences in allele frequencies between cases and controls due to systematic differences in ancestry rather than association of genes with disease). One approach to control for ancestry is to perform Principal Component Analysis (PCA). \n",
    "\n",
    "Hail allows one to easily perform PCA using a built in function. Let's perform PCA and plot the results to see if we notice anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68c320-1003-4c7f-aacb-c1a6bf17298b",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "25e85047-34f4-4596-8470-b3e5a80b6504",
     "isComponent": true,
     "name": "Control for PCA",
     "parents": [
      {
       "id": "05b0adb7-effd-4822-88f7-595b1c8b07d4",
       "name": "Variant QC"
      },
      {
       "id": "420b6224-354a-41ab-911f-0b9f85782623",
       "name": "Initialize Hail"
      }
     ]
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eigenvalues, pcs, _ = hl.hwe_normalized_pca(filtered_mt.GT)\n",
    "filtered_mt = filtered_mt.annotate_cols(scores = pcs[filtered_mt.s].scores)\n",
    "\n",
    "p = hl.plot.scatter(filtered_mt.scores[0],\n",
    "                    filtered_mt.scores[1],\n",
    "                    label=filtered_mt.pheno.SuperPopulation,\n",
    "                    title='PCA', xlabel='PC1', ylabel='PC2')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8cf945-6f82-4f06-a3c4-783251a9758e",
   "metadata": {},
   "source": [
    "The scatter plot above plots each sample according to their first two principal components and colors the samples by their ancestry SuperPopulation (AFR = Africa, AMR = Admixed American, EAS = Eastern Asian, EUR = European, and SAS = South Asian). As we can see, several clusters emerge. Without going into too much detail, to account for ancestry potentially playing a part in our linear regression, we simply add our calculated principal components as co-variates in our statistical test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae0afce-d4f6-44ba-8a43-933cd1b8a75b",
   "metadata": {},
   "source": [
    "### 5. Final GWAS controlling for Population Stratification\n",
    "\n",
    "Let us add in the first few principal components (stored in a variable called \"filterd_mt.scores\") as co-variates in our statistical test and re-run our GWAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab4843-6974-4168-9a06-e7d7ae442c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is where we actually add our principal components and ancestry information into our GWAS function call. Take a look at the commented line before to see how we modify our covariates.\n",
    "gwas = hl.linear_regression_rows(\n",
    "    y=filtered_mt.pheno.CaffeineConsumption,\n",
    "    x=filtered_mt.GT.n_alt_alleles(),\n",
    "    # This is where we added in additional covariates (in our case the principal components). In Python, array numbering starts at 0, so we include filtered_mt.scores[0], filtered_mt.scores[1], filtered_mt.scores[2] to account for the first three PCs.\n",
    "    covariates=[1.0, filtered_mt.pheno.isFemale, filtered_mt.scores[0], filtered_mt.scores[1], filtered_mt.scores[2]]) \n",
    "p = hl.plot.manhattan(gwas.p_value)\n",
    "show(p)\n",
    "p = hl.plot.qq(gwas.p_value)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1937c3-5f80-4e5e-a19f-4c6c142e186b",
   "metadata": {},
   "source": [
    "Now that's a much better looking skyline. From the QQ-plot, we see that most points do fall on the center line. From the Manhattan plot, we see that most variants are not significant but we do have some on Chromosome 8 that have met our significance threshold. Remember this is a synthetic phenotype so there probably are not any variants on Chromosome 8 that are associated with CaffieneConsumption, but it is always nice to see results!\n",
    "\n",
    "Feel free to use your cursor and hover over the variants to find more information about their chromosomal position and p-value. If you simply want a table with that information, you can run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d086995-7eb2-4398-a59a-963e8d63b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints out top 10 GWAS results sorted by p-value\n",
    "gwas.order_by(\"p_value\").show(10)\n",
    "# Simply for evaluation purposes, getting time taken for tutorial\n",
    "end = time.time()\n",
    "print(\"Total time (seconds): \" + str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef8492e-ef3b-494f-8b28-bfcf9a4f008a",
   "metadata": {},
   "source": [
    "### 6. Congratulations!\n",
    "\n",
    "You have just completed an entire GWAS from start to finish! To summarize:\n",
    "1. We first set up our work environment and loaded in our data\n",
    "2. We then performed some sample and variant QC to filter our dataset\n",
    "3. We performed an initial GWAS and were met with noisy results\n",
    "4. We applied PCA and accounted for ancestry playing a role in impacting our phenotype\n",
    "5. We performed a final GWAS accounting for ancestry\n",
    "\n",
    "Feel free to explore some of the other notebooks available or rerun this experiment with your own data!"
   ]
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
